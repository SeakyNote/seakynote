**演讲人**：吴迪（影眸科技 CEO）
**演讲时间**：2025年12月28日

---

## 一、 背景与起源：从实验室到创业团队

### 1.1 起源于上海科技大学
影眸科技（Yingmou Technology）孵化自上海科技大学（ShanghaiTech）。团队核心成员源于2016年加入的计算摄影与图形学实验室（MARS实验室）。在导师虞晶怡教授的带领下，团队从2016年开始深耕3D重建、数字人及光场技术。

### 1.2 创业初期的心态转变
团队从科研背景走向商业化过程中，经历了从“技术思维”到“产品思维”的转变。
*   **科研思维**：关注突破上界（Upper Bound），哪怕只有5%的Case成功也能发论文（Best Paper）。
*   **产品思维**：必须兜底下界（Lower Bound），需保证80%以上的Case成功，且必须符合工业界的生产标准（Production Ready）。

---

## 二、 早期探索与试错：寻找PMF（产品市场契合点）

### 2.1 探索一：光场采集系统（Light Stage）
*   **尝试**：2016-2020年间，团队搭建了国内首个动态体积摄影和3D重建系统，以及主动式光照采集系统（190多个光源、高速相机）。
*   **目标**：捕捉物体在不同光照下的材质信息（PBR），服务于影视特效。
*   **挫折**：早期向市场推广（如《流浪地球2》团队）时发现，这种极高端的影视级设备应用场景极窄，被当头一棒：“这玩意有啥用？”。
*   **教训**：技术必须与实际工业需求适配，不能只做束之高阁的科研成果。

### 2.2 探索二：C端应用尝试（“老婆生成器”）
*   **尝试**：2021年发布了一款二次元角色生成APP（类似于早期的ControlNet思路），利用GAN技术通过色块生成头像。
*   **数据**：两周内获得160万注册用户，在App Store和TapTap霸榜。
*   **结果**：仅盈利6000元人民币。
*   **放弃原因**：
    1.  团队缺乏社区运营基因。
    2.  判断半年内AI生图（这也是后来Midjourney的赛道）会爆发，团队决定回归更擅长的3D领域。

### 2.3 探索三：微米级人脸扫描（第二代光场）
*   **回归3D**：基于所有试错，团队锁定了“Production Ready”的标准。
*   **成果**：研发了能生成高精度PBR材质、不论是毛孔还是结构都极度逼真的扫描设备。
*   **商业化**：服务了Unity、More VFX等客户，将传统影视/游戏资产制作周期从3个月压缩至1天，并能直接接入Maya/Unreal等管线。
*   **意义**：积累了数千个高精度3D资产数据，为后续的AI大模型训练奠定了基础。

---

## 三、 技术路线转型：从扫描到原生3D生成

### 3.1 融资危机与背水一战
在2023年准备融资并在技术上转向3D生成时，遭遇美元基金LP限制等不可抗力，导致融资失败，现金流一度只剩3个月。团队通过裁员、降薪及原有业务造血，硬撑着进行了技术路线的豪赌——**原生3D生成**。

### 3.2 技术路线选择：原生3D vs 2D转3D
当时市场主流（如OpenAI、Google部分研究）倾向于“2D升3D”（先生成多视角图，再用NeRF/MVS重建）。
*   **2D转3D的弊端**：降维再升维会导致信息丢失，表面噪声大、有伪影、多头问题，无法满足工业界“干净拓扑”的需求。
*   **影眸的选择（Native 3D）**：直接在3D空间内进行标注、训练和监督。
*   **结果**：赌对了。2023年初发布的Demo实现了代差级领先，其底层模型Clay获得了SIGGRAPH最佳论文提名。

---

## 四、 核心产品能力：Rodin（罗丹）平台

影眸科技推出了Rodin平台，核心理念是将AI的可控权交给用户，实现真正可用的3D资产生成。

### 4.1 核心功能与特性
*   **高生成质量**：表面光滑，布线规整（Topology），不仅是“看起来像”，而是“能用”。
*   **3D ControlNet（可控生成）**：
    *   **Bounding Box**：控制长宽高比例。
    *   **Voxel（体素）**：类似《我的世界》堆方块，控制大体形状（如生成同一角色的不同皮肤）。
    *   **Point Cloud（点云）**：最强控制，保证生成模型与输入点云形状一致。
*   **多种风格模型**：
    *   **Voxel版**：高精度，耗时较长。
    *   **Speedy版**：8秒快速生成。
    *   **Zero版**：过滤高频细节，适合风格化游戏（如《蛋仔派对》）。

### 4.2 第二代模型（Gen 2）的突破
2024年10月发布的新一代模型，参数量提升4倍，质量提升。
*   **分部件生成（Explosive Map）**：全球首个可生成爆炸图（拆分件）的模型。
    *   **意义**：符合工业与游戏制作逻辑（如车辆轮子需拆分、角色关节需绑定）。
    *   **技术路径**：非后期分割，而是直接生成拆分状态，再反向追踪，保证切口平整。
*   **Deep Thinking（思维链）**：利用分部件生成来提升整体质量，对各部件分别优化（Test-time scaling），质量提升3-5倍。

### 4.3 工作流集成
支持GLB/OBJ导出，提供插件直接打通Blender、Unity等DCC（数字内容创作）软件，实现无缝衔接。

---

## 五、 未来展望：3D与世界的生成

### 5.1 3D生成 vs 视频生成
*   **视频生成的局限**：主体一致性差（旋转时物体变形）、物理属性错误（缺乏重力、碰撞逻辑）。
*   **3D生成的优势**：具有物理属性（Physics），主体绝对一致。
*   **融合路径**：未来是Hybrid模式。
    *   **3D控制结构与物理**：负责主体运动、交互、物理模拟。
    *   **视频生成渲染画面**：负责最终的像素级渲染（光影、甚至假草等背景）。
    *   **演示成果**：展示了通过3D控制相机轨迹和物体运动，再由视频模型渲染画面的Demo，实现了高一致性和物理正确性。

### 5.2 终极目标：世界模型（World Model）
*   **愿景**：从生成单个“Asset（资产）”进化到生成“Scene（场景）”乃至“World（世界）”。
*   **为具身智能服务**：AGI（通用人工智能）若要进入物理世界（Physical AI），需要无穷无尽的虚拟3D场景进行交互训练（如机器人学习抓取）。
*   **学术成果**：发表了名为**CARS**的学术成果（SIGGRAPH 2024最佳论文），实现了从一张图生成一个物理属性完全正确的3D小场景。

---

## 六、 Q&A 观点摘要

*   **关于竞争（如腾讯）**：大厂做全生态，初创公司做垂类工具。影眸更侧重于将工具能力（如Edit、拆分、Agent）做深，嵌入管线。
*   **关于商业化**：
    *   目前B端（企业）和C端（个人/专业用户）收入约为6:4。
    *   B端尚未跑出完美的PMF（产品市场契合点），用法极度分散（游戏、3D打印、室内设计）。
    *   C端/PLG（产品驱动增长）是明年发力点，预计营收目标从数百万美元增长至3000-5000万美元。
*   **关于开源（如Trellis）**：开源有助于降低门槛，吸引关注。闭源模型（如Rodin）将保持技术领先，形成互补。
*   **关于工业设计**：目前AI生成精度尚难达到航天级（如发动机），但在外观设计（如车企油泥模型替代、充电宝打样）已有落地。未来需结合参数化建模。
*   **关于发论文**：对于产品型公司，发高质量论文（如SIGGRAPH）主要用于PR（建立行业地位、获取大客户信任）以及满足实习生的学术需求，但核心仍是产品落地。

## 整理
- faster-whisper
- google/gemini-3-pro-preview